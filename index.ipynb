{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sklearn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "boston = load_boston()\n",
    "boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.413229</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.439316</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>-0.625796</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.387217</td>\n",
       "      <td>-0.418147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.415249</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.234548</td>\n",
       "      <td>0.288933</td>\n",
       "      <td>-0.716639</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.500850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.413447</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>-0.773684</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.983048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.407764</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.725672</td>\n",
       "      <td>0.736996</td>\n",
       "      <td>-0.668437</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.403225</td>\n",
       "      <td>-0.865302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.415000</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.362767</td>\n",
       "      <td>0.434732</td>\n",
       "      <td>-0.613246</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.669058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1   -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2   -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3   -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4   -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501 -0.413229 -0.487722  0.115738 -0.272599  0.158124  0.439316  0.018673   \n",
       "502 -0.415249 -0.487722  0.115738 -0.272599  0.158124 -0.234548  0.288933   \n",
       "503 -0.413447 -0.487722  0.115738 -0.272599  0.158124  0.984960  0.797449   \n",
       "504 -0.407764 -0.487722  0.115738 -0.272599  0.158124  0.725672  0.736996   \n",
       "505 -0.415000 -0.487722  0.115738 -0.272599  0.158124 -0.362767  0.434732   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1    0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2    0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3    1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4    1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "501 -0.625796 -0.982843 -0.803212  1.176466  0.387217 -0.418147  \n",
       "502 -0.716639 -0.982843 -0.803212  1.176466  0.441052 -0.500850  \n",
       "503 -0.773684 -0.982843 -0.803212  1.176466  0.441052 -0.983048  \n",
       "504 -0.668437 -0.982843 -0.803212  1.176466  0.403225 -0.865302  \n",
       "505 -0.613246 -0.982843 -0.803212  1.176466  0.441052 -0.669058  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = boston.target\n",
    "X = boston.data\n",
    "X_scaled = scale(X)\n",
    "df_features = pd.DataFrame(X_scaled, columns = boston.feature_names)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63919994,  0.71386698,  0.58702344,  0.07923081, -0.25294154])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "baselineModel = linreg.fit(df_features,y)\n",
    "linreg.score(X,y)\n",
    "\n",
    "cross_val_score(baselineModel,X,y, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1,), (2,), (3,), (4,)],\n",
       " [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)],\n",
       " [(1, 2, 3), (1, 2, 4), (1, 3, 4), (2, 3, 4)],\n",
       " [(1, 2, 3, 4)]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(list(combinations(s, r)) for r in range(len(s)+1)))\n",
    "powerset([1,2,3,4])\n",
    "\n",
    "thing = []\n",
    "for x in ([combinations([1,2,3,4],r) for r in [1,2,3,4]]):\n",
    "    thing.append(list(x))\n",
    "thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('CRIM', 'ZN')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('CRIM', 'ZN')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-80ae0dafab0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallSubs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlinreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbaselineModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcrossValAverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaselineModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcrossValScores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrossValAverage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('CRIM', 'ZN')"
     ]
    }
   ],
   "source": [
    "allSubs = powerset(df_features.columns)\n",
    "crossValScores = []\n",
    "for x in allSubs[14:]:\n",
    "    linreg = LinearRegression()\n",
    "    baselineModel = linreg.fit(df_features[x],y)\n",
    "    crossValAverage = cross_val_score(baselineModel,X,y, scoring = 'r2').mean()\n",
    "    crossValScores.append(crossValAverage)\n",
    "display(sorted(crossValScores)[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                   order='C')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolyModel = PolynomialFeatures()\n",
    "PolyModel.fit(df_features[['CRIM']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RM', 2, 0.6489219558037129),\n",
       " ('RM', 3, 0.636164881065573),\n",
       " ('RM', 4, 0.6231113421411342),\n",
       " ('LSTAT', 4, 0.5274148762884813),\n",
       " ('LSTAT', 3, 0.5100575567350117),\n",
       " ('LSTAT', 2, 0.5038815917379018),\n",
       " ('DIS', 3, 0.43725671678801714),\n",
       " ('B', 2, 0.4233969609143496),\n",
       " ('B', 3, 0.4157775831868709),\n",
       " ('DIS', 2, 0.40523227541270435),\n",
       " ('DIS', 4, 0.38011157221199426),\n",
       " ('AGE', 3, 0.37127845308013013),\n",
       " ('AGE', 2, 0.37058236058090716),\n",
       " ('INDUS', 2, 0.36900010662045446),\n",
       " ('AGE', 4, 0.36416005748900265),\n",
       " ('PTRATIO', 2, 0.35834298290332056),\n",
       " ('CHAS', 3, 0.35327592439588357),\n",
       " ('CHAS', 4, 0.35327592439588246),\n",
       " ('CHAS', 2, 0.35327592439588035),\n",
       " ('ZN', 2, 0.3519685947985766),\n",
       " ('CRIM', 2, 0.3469113637678257),\n",
       " ('PTRATIO', 3, 0.34672665794499247),\n",
       " ('PTRATIO', 4, 0.34313200638359176),\n",
       " ('TAX', 4, 0.34238075790529754),\n",
       " ('RAD', 4, 0.340389725446876),\n",
       " ('CRIM', 3, 0.33833845834722304),\n",
       " ('ZN', 3, 0.33828069669371275),\n",
       " ('ZN', 4, 0.33268594152657127),\n",
       " ('NOX', 2, 0.3287775054260874),\n",
       " ('RAD', 2, 0.32840935104638813),\n",
       " ('NOX', 4, 0.3207313408609015),\n",
       " ('RAD', 3, 0.3186934662886861),\n",
       " ('TAX', 3, 0.31573935132839936),\n",
       " ('INDUS', 3, 0.31234244977599807),\n",
       " ('TAX', 2, 0.2997753200888103),\n",
       " ('NOX', 3, 0.27321107835529357),\n",
       " ('INDUS', 4, 0.10587435964621675),\n",
       " ('CRIM', 4, 0.014021227059185338),\n",
       " ('B', 4, -2.6102501077502076)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = []\n",
    "for degree in [2,3,4]:\n",
    "    polyModel = PolynomialFeatures(degree, include_bias = False)\n",
    "    for x in df_features.columns:\n",
    "        data = pd.concat([df_features.copy().drop(columns = x), pd.DataFrame(polyModel.fit_transform(df_features[[x]]))], axis = 1)\n",
    "#         display(data)\n",
    "        linreg = LinearRegression()\n",
    "        score = np.mean(cross_val_score(linreg, data, y, scoring = 'r2'))\n",
    "        tuples.append((x, degree,score))\n",
    "sorted(tuples, key = lambda x: x[2], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'criterion')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "model_bic = LassoLarsIC(criterion = 'bic')\n",
    "model_bic.fit(df_features, y)\n",
    "alpha_bic = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion = 'aic')\n",
    "model_aic.fit(df_features, y)\n",
    "alpha_aic = model_bic.alpha_\n",
    "\n",
    "criterion_ = model_aic.criterion_\n",
    "plt.semilogx(model_aic.alphas_, criterion_, '--', color='red',\n",
    "             linewidth=3, label='%s criterion')\n",
    "plt.axvline(model_aic.alpha_, color='red', linewidth=3,\n",
    "            label='alpha: %s estimate')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('criterion')\n",
    "\n",
    "criterion_ = model_bic.criterion_\n",
    "plt.semilogx(model_bic.alphas_, criterion_, '--', color='blue',\n",
    "             linewidth=3, label='%s criterion')\n",
    "plt.axvline(model_bic.alpha_, color='blue', linewidth=3,\n",
    "            label='alpha: %s estimate')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('criterion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7579387124036658\n",
      "21.898409699087384\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features,y, random_state = 1)\n",
    "\n",
    "# Code for baseline model\n",
    "lasso = Lasso(alpha = model_aic.alpha_)\n",
    "baselineModel = lasso.fit(X_train, y_train)\n",
    "\n",
    "print(np.mean(cross_val_score(baselineModel,X_test,y_test, scoring = 'r2')))\n",
    "print(mean_squared_error(y_test, baselineModel.predict(X_test)))\n",
    "# Print R2 and MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7578898111081535\n",
      "21.897765396049497\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features,y, random_state = 1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg = LinearRegression()\n",
    "baselineModel = linreg.fit(X_train, y_train)\n",
    "\n",
    "print(np.mean(cross_val_score(baselineModel,X_test,y_test, scoring = 'r2')))\n",
    "print(mean_squared_error(y_test, baselineModel.predict(X_test)))\n",
    "# Print R2 and MSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75955590883543\n",
      "22.034183743300478\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = None\n",
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features,y, random_state = 1)\n",
    "\n",
    "# Code for baseline model\n",
    "lasso = Lasso(alpha = model_bic.alpha_)\n",
    "baselineModel = lasso.fit(X_train, y_train)\n",
    "\n",
    "print(np.mean(cross_val_score(baselineModel,X_test,y_test, scoring = 'r2')))\n",
    "print(mean_squared_error(y_test, baselineModel.predict(X_test)))\n",
    "# Print R2 and MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
